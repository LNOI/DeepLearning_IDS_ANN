{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.8/site-packages (1.6.3)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: click<8,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.8/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: absl-py<=0.11,>=0.9 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.11.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.8.10)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.44.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.15)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle<2,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.6.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.1.16)\n",
      "Requirement already satisfied: kubernetes<13,>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (12.0.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (3.20.1)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py<=0.11,>=0.9->kfp) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.8/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.8/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /opt/conda/lib/python3.8/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (2.10.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.8/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.8/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (3.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp) (4.9)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp) (65.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.28.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema<4,>=3.0.1->kfp) (22.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2022.6.15)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.11)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.8/site-packages (from kubernetes<13,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.8/site-packages (from kubernetes<13,>=8.0.0->kfp) (1.4.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.8/site-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (1.56.4)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.8/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (2.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib->kubernetes<13,>=8.0.0->kfp) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp\n",
    "!mkdir -p saved_model\n",
    "from typing import NamedTuple\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kfp.components import func_to_container_op\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    url : str,\n",
    "    X_train_path:  OutputPath(\"PKL\"),\n",
    "    Y_train_path:  OutputPath(\"PKL\"),\n",
    "    X_test_path:  OutputPath(\"PKL\"),\n",
    "    Y_test_path:  OutputPath(\"PKL\")\n",
    "):  \n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.wrappers.scikit_learn import KerasClassifier\n",
    "    import joblib\n",
    "    import wget\n",
    "\n",
    "    wget.download(url)\n",
    "    cols=\"\"\"duration,\n",
    "    protocol_type,\n",
    "    service,\n",
    "    flag,\n",
    "    src_bytes,\n",
    "    dst_bytes,\n",
    "    land,\n",
    "    wrong_fragment,\n",
    "    urgent,\n",
    "    hot,\n",
    "    num_failed_logins,\n",
    "    logged_in,\n",
    "    num_compromised,\n",
    "    root_shell,\n",
    "    su_attempted,\n",
    "    num_root,\n",
    "    num_file_creations,\n",
    "    num_shells,\n",
    "    num_access_files,\n",
    "    num_outbound_cmds,\n",
    "    is_host_login,\n",
    "    is_guest_login,\n",
    "    count,\n",
    "    srv_count,\n",
    "    serror_rate,\n",
    "    srv_serror_rate,\n",
    "    rerror_rate,\n",
    "    srv_rerror_rate,\n",
    "    same_srv_rate,\n",
    "    diff_srv_rate,\n",
    "    srv_diff_host_rate,\n",
    "    dst_host_count,\n",
    "    dst_host_srv_count,\n",
    "    dst_host_same_srv_rate,\n",
    "    dst_host_diff_srv_rate,\n",
    "    dst_host_same_src_port_rate,\n",
    "    dst_host_srv_diff_host_rate,\n",
    "    dst_host_serror_rate,\n",
    "    dst_host_srv_serror_rate,\n",
    "    dst_host_rerror_rate,\n",
    "    dst_host_srv_rerror_rate\"\"\"\n",
    "\n",
    "    columns=[]\n",
    "    for c in cols.split(','):\n",
    "        if(c.strip()):\n",
    "            columns.append(c.strip())\n",
    "    columns.append('target')\n",
    "\n",
    "    attacks_types = {\n",
    "    'normal': 'normal',\n",
    "    'back': 'dos',\n",
    "    'buffer_overflow': 'u2r',\n",
    "    'ftp_write': 'r2l',\n",
    "    'guess_passwd': 'r2l',\n",
    "    'imap': 'r2l',\n",
    "    'ipsweep': 'probe',\n",
    "    'land': 'dos',\n",
    "    'loadmodule': 'u2r',\n",
    "    'multihop': 'r2l',\n",
    "    'neptune': 'dos',\n",
    "    'nmap': 'probe',\n",
    "    'perl': 'u2r',\n",
    "    'phf': 'r2l',\n",
    "    'pod': 'dos',\n",
    "    'portsweep': 'probe',\n",
    "    'rootkit': 'u2r',\n",
    "    'satan': 'probe',\n",
    "    'smurf': 'dos',\n",
    "    'spy': 'r2l',\n",
    "    'teardrop': 'dos',\n",
    "    'warezclient': 'r2l',\n",
    "    'warezmaster': 'r2l',\n",
    "    }\n",
    "    path = \"kddcup.data_10_percent.gz\"\n",
    "    df = pd.read_csv(path,names=columns)\n",
    "\n",
    "    #Adding Attack Type column\n",
    "    df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])\n",
    "    #Finding categorical features\n",
    "    num_cols = df._get_numeric_data().columns\n",
    "\n",
    "    cate_cols = list(set(df.columns)-set(num_cols))\n",
    "    cate_cols.remove('target')\n",
    "    cate_cols.remove('Attack Type')\n",
    "    df = df.dropna('columns')# drop columns with NaN\n",
    "\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]]# keep columns where there are more than 1 unique values\n",
    "\n",
    "    corr = df.corr()\n",
    "    df.drop('num_root',axis = 1,inplace = True)\n",
    "    df.drop('srv_serror_rate',axis = 1,inplace = True)\n",
    "    df.drop('srv_rerror_rate',axis = 1, inplace=True)\n",
    "    df.drop('dst_host_srv_serror_rate',axis = 1, inplace=True)\n",
    "    df.drop('dst_host_serror_rate',axis = 1, inplace=True)\n",
    "    df.drop('dst_host_rerror_rate',axis = 1, inplace=True)\n",
    "    df.drop('dst_host_srv_rerror_rate',axis = 1, inplace=True)\n",
    "    df.drop('dst_host_same_srv_rate',axis = 1, inplace=True)\n",
    "    df_std = df.std()\n",
    "    df_std = df_std.sort_values(ascending = True)\n",
    "    #protocol_type feature mapping\n",
    "    pmap = {'icmp':0,'tcp':1,'udp':2}\n",
    "    df['protocol_type'] = df['protocol_type'].map(pmap)\n",
    "    #flag feature mapping\n",
    "    fmap = {'SF':0,'S0':1,'REJ':2,'RSTR':3,'RSTO':4,'SH':5 ,'S1':6 ,'S2':7,'RSTOS0':8,'S3':9 ,'OTH':10}\n",
    "    df['flag'] = df['flag'].map(fmap)\n",
    "    df.drop('service',axis = 1,inplace= True)\n",
    "    df = df.drop(['target',], axis=1)\n",
    "    print(df.shape)\n",
    "\n",
    "    # Target variable and train set\n",
    "    Y = df[['Attack Type']]\n",
    "    X = df.drop(['Attack Type',], axis=1)\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "\n",
    "    # Split test and train data \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "    joblib.dump(X_train,X_train_path)\n",
    "    joblib.dump(Y_train,Y_train_path)\n",
    "    joblib.dump(X_test,X_test_path)\n",
    "    joblib.dump(Y_test,Y_test_path)\n",
    "    \n",
    "    print(X_train.shape, X_test.shape)\n",
    "    print(Y_train.shape, Y_test.shape)\n",
    "    \n",
    "prepare_data_op = func_to_container_op(\n",
    "    func =  prepare_data ,\n",
    "    packages_to_install = [\n",
    "        \"joblib\",\n",
    "        \"keras\",\n",
    "        \"tensorflow\",\n",
    "        \"wget\",\n",
    "        \"scikit-learn\",\n",
    "        \"matplotlib\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"seaborn\"\n",
    "    ]   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(\n",
    "    X_train_path:  InputPath(\"PKL\"),\n",
    "    Y_train_path:  InputPath(\"PKL\"),\n",
    "    X_test_path:  InputPath(\"PKL\"),\n",
    "    Y_test_path:  InputPath(\"PKL\"),\n",
    "    model_dir : OutputPath(str)\n",
    "):  \n",
    "    import os\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    import joblib\n",
    "    import wget\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    lb = LabelEncoder()\n",
    "    X_train = joblib.load(X_train_path)\n",
    "    Y_train = joblib.load(Y_train_path)\n",
    "    X_test = joblib.load(X_test_path)\n",
    "    Y_test = joblib.load(Y_test_path)\n",
    "        \n",
    "    Y_train = lb.fit_transform(Y_train)\n",
    "    Y_test = lb.fit_transform(Y_test)\n",
    "    def create_model():\n",
    "      model = tf.keras.models.Sequential([\n",
    "          keras.layers.Dense(30, activation='relu', input_dim=30,kernel_initializer='random_uniform'),\n",
    "          keras.layers.Dense(1,activation='sigmoid',kernel_initializer='random_uniform'),\n",
    "          keras.layers.Dense(5, activation='softmax')\n",
    "      ])\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "      return model\n",
    "\n",
    "    model = create_model()\n",
    "    checkpoint_path = \"training_1/cp.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "          Y_train,  \n",
    "          epochs=1,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test, Y_test))\n",
    "    \n",
    "    model.save(model_dir)\n",
    "    print(f\"Model saved {model_dir}\")\n",
    "    print(os.listdir(model_dir))\n",
    "    \n",
    "train_op = func_to_container_op(\n",
    "    func = train_data  ,\n",
    "    packages_to_install = [\n",
    "        \"joblib\",\n",
    "        \"tensorflow\",\n",
    "        \"wget\",\n",
    "        \"scikit-learn\",\n",
    "        \"pandas\",\n",
    "    ]   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model_dir : InputPath(str),\n",
    "    X_test_path:  InputPath(\"PKL\"),\n",
    "    Y_test_path:  InputPath(\"PKL\")\n",
    ") -> NamedTuple(\"EvaluationOutput\", [(\"mlpipeline_metrics\", \"Metrics\")]):\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from collections import namedtuple\n",
    "    lb = LabelEncoder()\n",
    "    X_test = joblib.load(X_test_path)\n",
    "    Y_test = joblib.load(Y_test_path)\n",
    "    Y_test = lb.fit_transform(Y_test)\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "    model.summary()\n",
    "    loss, accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
    "    metrics = {\n",
    "        \"metrics\": [\n",
    "            {\"name\": \"loss\", \"numberValue\": str(loss), \"format\": \"PERCENTAGE\"},\n",
    "            {\"name\": \"accuracy\", \"numberValue\": str(accuracy), \"format\": \"PERCENTAGE\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "    return out_tuple(json.dumps(metrics))   \n",
    "evl_op = func_to_container_op(\n",
    "    func = evaluate_model,\n",
    "    packages_to_install = [\n",
    "        \"joblib\",\n",
    "        \"tensorflow\",\n",
    "        \"scikit-learn\"\n",
    "    ]   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitoring(\n",
    "):\n",
    "    pass\n",
    "monitoring_op = func_to_container_op(\n",
    "    func = monitoring  ,\n",
    "    packages_to_install = [\n",
    "        \"joblib\",\n",
    "        \"keras\",\n",
    "        \"wget\",\n",
    "        \"scikit-learn\",\n",
    "        \"matplotlib\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"seaborn\"\n",
    "    ]   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://10.64.140.43.nip.io/pipeline/#/experiments/details/7e5b1b66-403e-4ccc-b12f-b77f8b7a521c\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://10.64.140.43.nip.io/pipeline/#/runs/details/2eaada2f-6116-478f-95e0-e358d68adc5c\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=2eaada2f-6116-478f-95e0-e358d68adc5c)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "@dsl.pipeline(\n",
    "  name='Deep Learning IDS/IPS',\n",
    "  description='Pipeline'\n",
    ")\n",
    "def my_pipeline(url):\n",
    "    prepare_data_task = prepare_data_op(url)\n",
    "    train_task = train_op(x_train= prepare_data_task.outputs[\"X_train\"],\n",
    "                          y_train= prepare_data_task.outputs[\"Y_train\"],\n",
    "                          x_test= prepare_data_task.outputs[\"X_test\"],\n",
    "                          y_test= prepare_data_task.outputs[\"Y_test\"],\n",
    "                          ) \n",
    "    evl_task = evl_op(model_dir=train_task.outputs[\"model_dir\"],\n",
    "                          x_test= prepare_data_task.outputs[\"X_test\"],\n",
    "                          y_test= prepare_data_task.outputs[\"Y_test\"]\n",
    "                     ) \n",
    "    # monitoring_task = monitoring_op() \n",
    "\n",
    "session_cookies = \"MTY3MDM3NzgxNHxOd3dBTkVsWFUwOVpORUZMV1VkWVZWVlhRazQyTjBGSVdrVklURXREVFVnMU4wWlNXRTVMVVVwUE4xY3lTRmxUTWxWSU5WUmFTVkU9fNsIv8kMYn9FxRmsuD6HJPn8tqXZDuYXmIkjQuj4qn0r\"\n",
    "HOST = \"http://10.64.140.43.nip.io\"\n",
    "client = kfp.Client(\n",
    "  host= f\"{HOST}/pipeline\",\n",
    "  cookies = f\"authservice_session={session_cookies}\",\n",
    "  namespace=\"admin\"\n",
    ")\n",
    "redirect = 0\n",
    "if redirect:\n",
    "    client.create_run_from_pipeline_func(\n",
    "      my_pipeline,\n",
    "      arguments={\n",
    "        'url': 'http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz'\n",
    "      }\n",
    "    )\n",
    "else:\n",
    "    kfp.compiler.Compiler().compile(\n",
    "        pipeline_func = my_pipeline,\n",
    "        package_path = \"pipeline_dnn.yaml\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "275585cdcba9924c9c6e8df50545090134669d632506161f1f4ca47ec00107b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
