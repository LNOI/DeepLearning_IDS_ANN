{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2vl7hVHbffP18cHyApC+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LNOI/DeepLearning_IDS_ANN/blob/main/GAN_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVTcLkVSCh6i"
      },
      "outputs": [],
      "source": [
        "!pip install  seaborn\n",
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install wget\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import wget\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols=\"\"\"duration,protocol_type,service,flag,src_bytes,dst_bytes,land,wrong_fragment,urgent,hot,\n",
        "num_failed_logins,logged_in,num_compromised,root_shell,su_attempted,num_root,num_file_creations,num_shells,num_access_files,num_outbound_cmds,is_host_login,is_guest_login,\n",
        "count,srv_count,serror_rate,srv_serror_rate,rerror_rate,srv_rerror_rate,same_srv_rate,diff_srv_rate,srv_diff_host_rate,dst_host_count,dst_host_srv_count,\n",
        "dst_host_same_srv_rate,dst_host_diff_srv_rate,dst_host_same_src_port_rate,dst_host_srv_diff_host_rate,dst_host_serror_rate,dst_host_srv_serror_rate,dst_host_rerror_rate,dst_host_srv_rerror_rate\"\"\"\n",
        "columns=[]\n",
        "for c in cols.split(','):\n",
        "    if(c.strip()):\n",
        "       columns.append(c.strip())\n",
        "columns.append('target')\n",
        "# print(len(columns))\n",
        "attacks_types = {\n",
        "'normal': 'normal',\n",
        "'back': 'dos',\n",
        "'buffer_overflow': 'u2r',\n",
        "'ftp_write': 'r2l',\n",
        "'guess_passwd': 'r2l',\n",
        "'imap': 'r2l',\n",
        "'ipsweep': 'probe',\n",
        "'land': 'dos',\n",
        "'loadmodule': 'u2r',\n",
        "'multihop': 'r2l',\n",
        "'neptune': 'dos',\n",
        "'nmap': 'probe',\n",
        "'perl': 'u2r',\n",
        "'phf': 'r2l',\n",
        "'pod': 'dos',\n",
        "'portsweep': 'probe',\n",
        "'rootkit': 'u2r',\n",
        "'satan': 'probe',\n",
        "'smurf': 'dos',\n",
        "'spy': 'r2l',\n",
        "'teardrop': 'dos',\n",
        "'warezclient': 'r2l',\n",
        "'warezmaster': 'r2l',\n",
        "}\n",
        "path = \"https://github.com/LNOI/DeepLearning_IDS_ANN/raw/main/data/kddcup.data_10_percent.gz\"\n",
        "wget.download(path)\n",
        "df = pd.read_csv('kddcup.data_10_percent.gz',names=columns)\n",
        "#Adding Attack Type column\n",
        "df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])\n",
        "print(df.shape)\n",
        "num_cols = df._get_numeric_data().columns\n",
        "cate_cols = list(set(df.columns)-set(num_cols))\n",
        "cate_cols.remove('target')\n",
        "cate_cols.remove('Attack Type')\n",
        "df = df.dropna('columns')# drop columns with NaN\n",
        "df = df[[col for col in df if df[col].nunique() > 1]]\n",
        "\n",
        "df.drop('num_root',axis = 1,inplace = True)\n",
        "df.drop('srv_serror_rate',axis = 1,inplace = True)\n",
        "df.drop('srv_rerror_rate',axis = 1, inplace=True)\n",
        "df.drop('dst_host_srv_serror_rate',axis = 1, inplace=True)\n",
        "df.drop('dst_host_serror_rate',axis = 1, inplace=True)\n",
        "df.drop('dst_host_rerror_rate',axis = 1, inplace=True)\n",
        "df.drop('dst_host_srv_rerror_rate',axis = 1, inplace=True)\n",
        "df.drop('dst_host_same_srv_rate',axis = 1, inplace=True)\n",
        "\n",
        "#protocol_type feature mapping\n",
        "pmap = {'icmp':0,'tcp':1,'udp':2}\n",
        "df['protocol_type'] = df['protocol_type'].map(pmap)\n",
        "\n",
        "#flag feature mapping\n",
        "fmap = {'SF':0,'S0':1,'REJ':2,'RSTR':3,'RSTO':4,'SH':5 ,'S1':6 ,'S2':7,'RSTOS0':8,'S3':9 ,'OTH':10}\n",
        "df['flag'] = df['flag'].map(fmap)\n",
        "\n",
        "df.drop('service',axis = 1,inplace= True)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "\n",
        "df = df.drop(['target',], axis=1)\n",
        "print(df.shape)\n",
        "\n",
        "# Target variable and train set\n",
        "Y = df[['Attack Type']]\n",
        "X = df.drop(['Attack Type',], axis=1)\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "# Split test and train data \n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "Y_train = lb.fit_transform(Y_train)\n",
        "Y_test = lb.fit_transform(Y_test)\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(Y_train.shape, Y_test.shape)\n",
        "sample = X_train.shape[0]\n",
        "features = X_train.shape[1]\n",
        "X_train = np.reshape(X_train,(sample,features,1))\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spuXRBGgimi-",
        "outputId": "3eceb42f-aa45-4825-e5c9-521536c656f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(494021, 43)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-fb9de4317bc6>:46: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only\n",
            "  df = df.dropna('columns')# drop columns with NaN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(494021, 31)\n",
            "(330994, 30) (163027, 30)\n",
            "(330994,) (163027,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      keras.layers.LSTM(30,input_shape=(features,X_train.shape[2]),\n",
        "                            activation='tanh',recurrent_activation='hard_sigmoid'),\n",
        "      keras.layers.Dense(1,activation=\"tanh\")\n",
        "  ])\n",
        "  model.compile(optimizer='rmsprop',loss='mse', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "model.fit(X_train, \n",
        "          Y_train,  \n",
        "          epochs=1,\n",
        "          batch_size=64,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3vZctejjuoj",
        "outputId": "680522ff-9d3f-49a2-ab5d-65adcb92ca71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5172/5172 [==============================] - 163s 31ms/step - loss: 0.0398 - accuracy: 0.9681 - val_loss: 0.0277 - val_accuracy: 0.9803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc9246c3d00>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "Y_train_pred = model.predict(X_train)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLnwMLtgsumy",
        "outputId": "8f22682d-a771-4e21-d26d-f924d9bc3a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10344/10344 [==============================] - 54s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.amax(Y_train_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQFeeoVJszsY",
        "outputId": "b6e26026-49f4-42fc-a1d0-6bed1fd64efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.060773276"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zjcgWKg6bw0",
        "outputId": "384f6331-892f-4d4e-e19a-d787a13bc99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the real network traffic data\n",
        "# real_data = X_train\n",
        "\n",
        "# Create the generator network\n",
        "generator = tf.keras.Sequential()\n",
        "generator.add(tf.keras.layers.LSTM(30, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "generator.add(tf.keras.layers.Dense(X_train.shape[1]))\n",
        "\n",
        "# Create the discriminator network\n",
        "discriminator = tf.keras.Sequential()\n",
        "discriminator.add(tf.keras.layers.LSTM(30, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "discriminator.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the discriminator network\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Set the discriminator weights to be non-trainable\n",
        "for layer in discriminator.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Combine the generator and discriminator networks into a GAN\n",
        "gan = tf.keras.Sequential([generator, discriminator])\n",
        "\n",
        "# Compile the GAN\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the GAN\n",
        "for epoch in range(100):\n",
        "    # Generate synthetic data\n",
        "    synthetic_data = generator.predict(X_train)\n",
        "    \n",
        "    # Concatenate the synthetic data with real data\n",
        "    synthetic_data = np.reshape(synthetic_data,(synthetic_data.shape[0],synthetic_data.shape[1],1))\n",
        "    print(synthetic_data.shape)\n",
        "    print(X_train.shape)\n",
        "    combined_data = np.concatenate((X_train, synthetic_data))\n",
        "    \n",
        "    # Create labels for the real and synthetic data\n",
        "    real_labels = np.ones(X_train.shape[0])\n",
        "    synthetic_labels = np.zeros(synthetic_data.shape[0])\n",
        "    \n",
        "    # Concatenate the labels\n",
        "    combined_labels = np.concatenate((real_labels, synthetic_labels))\n",
        "    \n",
        "    # Train the discriminator on the combined data\n",
        "    d_loss, d_acc = discriminator.train_on_batch(combined_data, combined_labels)\n",
        "    \n",
        "    # Generate noise as input to the generator\n",
        "    noise = np.random.rand(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "    \n",
        "    # Train the GAN\n",
        "    g_loss = gan.train_on_batch(noise, real_labels)\n",
        "    \n",
        "    # Print loss and accuracy every 10 epochs\n",
        "    if epoch % 1 == 0:\n",
        "        print('epoch: {}, discriminator loss: {}, discriminator accuracy: {}, generator loss: {}'.format(epoch+1, d_loss, d_acc, g_loss))\n",
        "\n",
        "# Save the trained generator network\n",
        "generator.save('generator.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3guJsKA2JLZ",
        "outputId": "ebb8b553-52b4-4762-9736-5413195f505a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10344/10344 [==============================] - 48s 5ms/step\n",
            "(330994, 30, 1)\n",
            "(330994, 30, 1)\n"
          ]
        }
      ]
    }
  ]
}